# PromptAITest

A media album iOS app. I think I hit all the essential and secondary goals, but throughout this process I've realized a lot of what makes an application intuitive is consistency of features across views. If this were to be used by users, I'd like to spend another couple days refining upon this, adding things here and there to make using the app a really seamless experience.

The magic behind the scenes is the Many-to-Many Core Data relationship I set up between photos and folders. Working out the logic for photo-folder relationships was a mess before I found this feature; I think I spent a day just building the Folder view and half of the InsideFolder view (while manually handling relationships), and after I found CD relationships I spent the next day building everything else. Core Data is also just a really good framework to use for building scalable apps, since it focuses on the Object Graph while abstracting away the database layer, making for maintainable code (plus persistence is built in). I used an AVPlayer to handle videos, which is fine since it plays the video and is easy to implement, but it might be slowing things down. If this app were to be expanded upon, you might want to replace that with something more efficient.

I decided to sprinkle on an image classification model using CoreML, as I'm guessing PromptAI works with AI models. You can try it out by going into the individual image views by tapping on an image in the Gallery, and clicking 'Run Object Detection'. Not super hard to implement once you know how to use CoreML - this was just a proof of concept for future models.

To run this, download the repo and open it in Xcode. You can either use the ContentView.swift Preview or run the simulator. If the ML model isn't downloading properly, you can download it from here: https://developer.apple.com/machine-learning/models/
